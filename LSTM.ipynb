{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "mount_file_id": "1HmiMhhbKWKvqQlpeuCEJo_yb96TXSUMR",
      "authorship_tag": "ABX9TyMd8phpkSLpYqdJWTUsharC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucas-fpaiva/estatistica_pes/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "W-j2iq9NMsRm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bibliotecas"
      ],
      "metadata": {
        "id": "xfjxoFowjUPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jMfC_-7YE-4U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import random as python_random\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#IA\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import GRU\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funções"
      ],
      "metadata": {
        "id": "1hM-_6pGHg9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_seeds():\n",
        "   np.random.seed(4) \n",
        "   python_random.seed(9498)\n",
        "   tf.random.set_seed(9)\n",
        "\n",
        "reset_seeds() \n",
        "\n",
        "def data_import(txt):\n",
        "  global columns\n",
        "  columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
        "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
        "         ,\"sensor20\",\"sensor21\"]\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/cmap/\"+txt, sep= \"\\s+\", header = None,names=columns )\n",
        "  return df\n",
        "\n",
        "def add_rul(g):\n",
        "    g['RUL'] = max(g['cycle']) - g['cycle']\n",
        "    return g\n",
        "\n",
        "def add_cycle2(g):\n",
        "    g['cycle2'] = 362 - g['RUL']\n",
        "    return g\n",
        "\n",
        "def new_data(train_data):\n",
        "        new_data = train_data[[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"RUL\"]]\n",
        "        new_data['sensor']=[columns[5]]*train_data.shape[0]\n",
        "        new_data['sensor_value']= train_data[columns[5]]\n",
        "        for column in columns[5:]:\n",
        "            temp_data = train_data[[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"RUL\"]]\n",
        "            temp_data['sensor']=[column]*train_data.shape[0];\n",
        "            temp_data['sensor_value']= train_data[column];\n",
        "            new_data = pd.concat([new_data,temp_data],ignore_index=True)\n",
        "        return new_data \n",
        "\n",
        "def Suavisar(train_data, mm):\n",
        "        new_data = train_data[[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"RUL\"]]\n",
        "        new_data['sensor_value']= train_data[columns[5]]\n",
        "        for column in columns[5:]:\n",
        "            temp_data = train_data[[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"RUL\"]]\n",
        "            temp_data['sensor']=[column]*train_data.shape[0];\n",
        "            temp_data['sensor_value']= train_data[column];\n",
        "            new_data = pd.concat([new_data,temp_data],ignore_index=True)\n",
        "        return new_data \n"
      ],
      "metadata": {
        "id": "QI9CvtvEFFOt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dados"
      ],
      "metadata": {
        "id": "spGvzj89HozO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_FD001 = data_import(\"train_FD001.txt\") \n",
        "train_FD002 = data_import(\"train_FD002.txt\") \n",
        "train_FD003 = data_import(\"train_FD003.txt\") \n",
        "train_FD004 = data_import(\"train_FD004.txt\") \n",
        "\n",
        "train_FD001 = train_FD001.groupby('id').apply(add_rul)\n",
        "train_FD002 = train_FD002.groupby('id').apply(add_rul)\n",
        "train_FD003 = train_FD003.groupby('id').apply(add_rul)\n",
        "train_FD004 = train_FD004.groupby('id').apply(add_rul)\n",
        "\n",
        "train_FD001_2 = train_FD001.groupby('id').apply(add_cycle2)\n",
        "train_FD002_2 = train_FD002.groupby('id').apply(add_cycle2)\n",
        "train_FD003_2 = train_FD003.groupby('id').apply(add_cycle2)\n",
        "train_FD004_2 = train_FD004.groupby('id').apply(add_cycle2)\n",
        "\n",
        "new_train_FD001 = new_data(train_FD001) \n",
        "new_train_FD002 = new_data(train_FD002) \n",
        "new_train_FD003 = new_data(train_FD003) \n",
        "new_train_FD004 = new_data(train_FD004) "
      ],
      "metadata": {
        "id": "Seg6i9hal9CD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_list = []\n",
        "def add_rul(g):\n",
        "    global max_list\n",
        "    max_list.append(max(g['cycle']))\n",
        "    return g\n",
        "\n",
        "r = train_FD001.groupby('id').apply(add_rul)"
      ],
      "metadata": {
        "id": "RlhXbye4hD9n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = train_FD001[[\"RUL\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor7\",\"sensor12\",\"sensor15\",\"sensor17\",\"sensor20\",\"sensor21\"]]"
      ],
      "metadata": {
        "id": "VyQC6CB1JDiO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "x = scaler.fit_transform(dataset[[\"sensor2\",\"sensor3\",\"sensor4\",\"sensor7\",\"sensor12\",\"sensor15\",\"sensor17\",\"sensor20\",\"sensor21\"]])\n",
        "y = scaler.fit_transform(dataset[[\"RUL\"]])"
      ],
      "metadata": {
        "id": "pomrByvoPn2h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = scaler.fit_transform(dataset[[\"sensor2\",\"sensor3\",\"sensor4\",\"sensor7\",\"sensor12\",\"sensor15\",\"sensor17\",\"sensor20\",\"sensor21\"]])"
      ],
      "metadata": {
        "id": "b8Fz-3KKZ4FV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 30\n",
        "future = 1\n",
        "k=0\n",
        "X_train = []\n",
        "y_train = []\n",
        "for j in max_list:\n",
        "  print()\n",
        "  for i in range(look_back+k, k+j-future):\n",
        "    X_train.append(x[i-look_back:i])\n",
        "    y_train.append(y[i])\n",
        "  k=k+j\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "H_1Vn9fBSd6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe4dd63-b4e5-49b1-bc3b-d3e1cffa45a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo"
      ],
      "metadata": {
        "id": "LhGl4TAlMJCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Sequential()\n",
        "regressor.add(LSTM(units =128, return_sequences = True, input_shape = (X_train.shape[-2:])))\n",
        "regressor.add(LSTM(units = 32))\n",
        "regressor.add(Dense(units = 1, activation='LeakyReLU'))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "metadata": {
        "id": "qWQo3yiEWfgz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping#4\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "history = regressor.fit(X_train, y_train, epochs = 100, batch_size = 1024, validation_split=0.2,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93yywJwWjh7",
        "outputId": "66924197-78dd-4583-d4e3-0dc20e34b203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 14s 687ms/step - loss: 0.2627 - val_loss: 0.1606\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 8s 602ms/step - loss: 0.0588 - val_loss: 0.0965\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 8s 605ms/step - loss: 0.0486 - val_loss: 0.0873\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 8s 606ms/step - loss: 0.0461 - val_loss: 0.0832\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 9s 657ms/step - loss: 0.0442 - val_loss: 0.0823\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 8s 604ms/step - loss: 0.0417 - val_loss: 0.0775\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 10s 663ms/step - loss: 0.0418 - val_loss: 0.0673\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 8s 594ms/step - loss: 0.0375 - val_loss: 0.0669\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 8s 596ms/step - loss: 0.0331 - val_loss: 0.0575\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 8s 601ms/step - loss: 0.0329 - val_loss: 0.0884\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 8s 602ms/step - loss: 0.0322 - val_loss: 0.0609\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 8s 597ms/step - loss: 0.0299 - val_loss: 0.0567\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 8s 607ms/step - loss: 0.0290 - val_loss: 0.0547\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 8s 603ms/step - loss: 0.0283 - val_loss: 0.0585\n",
            "Epoch 15/100\n",
            " 3/14 [=====>........................] - ETA: 6s - loss: 0.0272"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testes"
      ],
      "metadata": {
        "id": "FStCiN5dMNse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
        "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
        "         ,\"sensor20\",\"sensor21\"]\n",
        "\n",
        "\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/cmap/test_FD001.txt\", sep= \"\\s+\", header = None,names=columns)"
      ],
      "metadata": {
        "id": "4ieDCFx7mCZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_list = []\n",
        "def add_rul(g):\n",
        "    global max_list\n",
        "    max_list.append(max(g['cycle']))\n",
        "    return g\n",
        "\n",
        "r = test_data.groupby('id').apply(add_rul)"
      ],
      "metadata": {
        "id": "wbORE_mmmR85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = scaler.transform(test_data[[\"sensor2\",\"sensor3\",\"sensor4\",\"sensor7\",\"sensor12\",\"sensor15\",\"sensor17\",\"sensor20\",\"sensor21\"]])"
      ],
      "metadata": {
        "id": "buXkY8_JmjBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 30\n",
        "future = 1\n",
        "k=0\n",
        "X_test = []\n",
        "for j in max_list:\n",
        "  X_test.append(x2[j+k-look_back:j+k])\n",
        "  k=k+j\n",
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "7oYaQL5Wmt0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = regressor.predict(X_test)\n",
        "y = scaler.fit_transform(dataset[[\"RUL\"]])\n",
        "resultado  = scaler.inverse_transform(resultado)\n"
      ],
      "metadata": {
        "id": "GRcsQo93dQ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = pd.read_csv(\"/content/drive/MyDrive/cmap/RUL_FD001.txt\", sep= \"\\s+\", header = None)\n",
        "p=resultado\n",
        "y_test = y_test.values\n",
        "p=np.reshape(p, len(p))\n",
        "y=np.array(y_test)\n",
        "y=np.reshape(y_test, len(y_test))"
      ],
      "metadata": {
        "id": "QVZ7VvIgGXY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "XkIMyV48ptiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y,p)"
      ],
      "metadata": {
        "id": "6ixYypikpvK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAE = []\n",
        "RMSE = []\n",
        "for i in range(100):\n",
        "  MAE.append(mean_absolute_error(y[0+i:i+1],p[0+i:i+1]))\n",
        "  RMSE.append(np.sqrt(mean_squared_error(y[0+i:i+1],p[0+i:i+1])))"
      ],
      "metadata": {
        "id": "ZRRXswUDf8ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RMSE_new = np.sqrt(mean_squared_error(y,p))\n",
        "print(\"RMSE (Taking only last examples): \", RMSE_new)"
      ],
      "metadata": {
        "id": "6z09D7giyt_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "#p,y_test = zip(*sorted(zip(p,y_test)))\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y=p,name=\"previsão\"))#,mode='markers',marker_symbol=\"x\"))\n",
        "fig.add_trace(go.Scatter(y=y,name=\"Dados\"))#,mode='markers'))\n",
        "fig.update_layout(title='Dados vs Previsão',\n",
        "                   xaxis_title='Unidade',\n",
        "                   yaxis_title='RUL')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "e2h-dsEYp3Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "#p,y_test = zip(*sorted(zip(p,y_test)))\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=y,y=p,mode='markers'))\n",
        "fig.update_layout(title='Dados vs Previsão',\n",
        "                   xaxis_title='Dados',\n",
        "                   yaxis_title='Previsão',\n",
        "                  width=700,height=700)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gcHUiLYwuKH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.save(\"LSTM_Mult.h5\")"
      ],
      "metadata": {
        "id": "lUDstfVyVRge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}